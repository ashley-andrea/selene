# ── LLM Provider ────────────────────────────────────────────────────────────
# Options: claude | crusoe | ollama
LLM_PROVIDER=crusoe

# Crusoe Managed Inference (dev/staging — OpenAI-compatible, api.crusoe.ai)
CRUSOE_API_KEY=your_crusoe_api_key
CRUSOE_MODEL=meta-llama/Llama-3.3-70B-Instruct

# Claude (production)
# ANTHROPIC_API_KEY=your_anthropic_api_key
# CLAUDE_MODEL=claude-sonnet-4-6

# Ollama (local)
# OLLAMA_MODEL=llama3.1

# ── ML Model APIs (Red Hat OpenShift) ──────────────────────────────────────
# Point to mock server during development
CLUSTER_API_URL=http://localhost:8001/cluster/predict
SIMULATOR_API_URL=http://localhost:8001/simulator/simulate

# ── LangSmith Tracing (free tier) ──────────────────────────────────────────
LANGCHAIN_TRACING_V2=false
# LANGCHAIN_API_KEY=your_langsmith_api_key
# LANGCHAIN_PROJECT=bc-agent-dev
