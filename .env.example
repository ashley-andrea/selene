# ── LLM Provider ────────────────────────────────────────────────────────────
# Options: claude | groq | ollama | openai_compat
LLM_PROVIDER=groq

# Groq (recommended for free-tier development)
GROQ_API_KEY=your_groq_api_key
GROQ_MODEL=llama-3.1-70b-versatile

# Claude (production)
# ANTHROPIC_API_KEY=your_anthropic_api_key
# CLAUDE_MODEL=claude-sonnet-4-6

# Ollama (local)
# OLLAMA_MODEL=llama3.1

# Generic OpenAI-compatible
# OPENAI_BASE_URL=https://api.example.com/v1
# OPENAI_API_KEY=your_key
# OPENAI_MODEL=model_name

# ── ML Model APIs (Red Hat OpenShift) ──────────────────────────────────────
# Point to mock server during development
CLUSTER_API_URL=http://localhost:8001/cluster/predict
SIMULATOR_API_URL=http://localhost:8001/simulator/simulate

# ── LangSmith Tracing (free tier) ──────────────────────────────────────────
LANGCHAIN_TRACING_V2=false
# LANGCHAIN_API_KEY=your_langsmith_api_key
# LANGCHAIN_PROJECT=bc-agent-dev
